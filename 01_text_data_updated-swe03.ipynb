{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Text Data in scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "1. Model building in scikit-learn (refresher)\n",
    "2. Representing text as numerical data\n",
    "3. Reading the SMS data\n",
    "4. Vectorizing the SMS data\n",
    "5. Building a Naive Bayes model\n",
    "6. Comparing Naive Bayes with logistic regression\n",
    "7. Calculating the \"spamminess\" of each token\n",
    "8. Creating a DataFrame from individual text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use print only as a function\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Model building in scikit-learn (refresher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__ = 'swe03'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "desired_width = 250\n",
    "pd.set_option('display.width',desired_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the csv file created in SQL Assistant, downloaded locally, and saved to C:\\NLP_Files\n",
    "#co_notes = pd.read_csv(\"C:\\\\NLP_Files\\\\cancelled_ord_notes.csv\")\n",
    "#co_notes.head(2)\n",
    "type(co_notes)\n",
    "\n",
    "#done_notes = pd.read_csv(\"C:\\\\NLP_Files\\\\done_ord_notes.csv\")\n",
    "#done_notes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add the Target column and value\n",
    "#co_notes['order'] = 0\n",
    "#co_notes.head(1)\n",
    "#type(co_notes[\"order\"])  # This is a Series \n",
    "#print(co_notes[\"order\"].dtype) # This is an int56\n",
    "#type(co_notes[\"CUST_ORD_NBR\"])  # This is a Series\n",
    "#done_notes['order'] = 1\n",
    "#done_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTV_FLG</th>\n",
       "      <th>ASSG_ASSOC_USER_ID</th>\n",
       "      <th>CLS_DT</th>\n",
       "      <th>CLS_USER_AUD_ID</th>\n",
       "      <th>CRT_SRC_MOD_ID</th>\n",
       "      <th>CRT_USER_AUD_ID</th>\n",
       "      <th>CUST_ORD_NBR</th>\n",
       "      <th>FLLW_UP_DT</th>\n",
       "      <th>LAST_UPD_SNSH_ID</th>\n",
       "      <th>LAST_UPD_TS</th>\n",
       "      <th>...</th>\n",
       "      <th>SRC_LAST_UPD_TS</th>\n",
       "      <th>STR_LOC_ID</th>\n",
       "      <th>SVC_LINE_NBR</th>\n",
       "      <th>SVC_NOTE_NBR</th>\n",
       "      <th>SVC_NOTE_TXT</th>\n",
       "      <th>TBIN_UPD_TS</th>\n",
       "      <th>TBIN_UPD_USER_ID</th>\n",
       "      <th>TKLR_BIN_CD</th>\n",
       "      <th>UPD_SRC_MOD_ID</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CUST_LOC</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>643,037_258</th>\n",
       "      <td>Y</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>MRT1803</td>\n",
       "      <td>643,037</td>\n",
       "      <td>?</td>\n",
       "      <td>4,258,089</td>\n",
       "      <td>1/16/2016 18:27:16.595</td>\n",
       "      <td>...</td>\n",
       "      <td>1/16/2016 14:57:24.905</td>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Customer came in to check on the ETA of the order</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>4.0</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643,037_258</th>\n",
       "      <td>Y</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>ERS015</td>\n",
       "      <td>643,037</td>\n",
       "      <td>?</td>\n",
       "      <td>4,275,111</td>\n",
       "      <td>1/21/2016 18:21:16.529</td>\n",
       "      <td>...</td>\n",
       "      <td>1/21/2016 11:15:35.507</td>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>01/21 eta 01/27</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>4.0</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643,037_258</th>\n",
       "      <td>Y</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>ERS015</td>\n",
       "      <td>643,037</td>\n",
       "      <td>?</td>\n",
       "      <td>4,275,111</td>\n",
       "      <td>1/21/2016 18:21:16.498</td>\n",
       "      <td>...</td>\n",
       "      <td>1/21/2016 11:30:39.932</td>\n",
       "      <td>258</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>01/21 Clyde will be calling the store on 01/27...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>4.0</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643,037_258</th>\n",
       "      <td>Y</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>ERS015</td>\n",
       "      <td>643,037</td>\n",
       "      <td>?</td>\n",
       "      <td>4,302,184</td>\n",
       "      <td>1/29/2016 18:23:40.695</td>\n",
       "      <td>...</td>\n",
       "      <td>1/29/2016 11:52:20.274</td>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>01/29 eta 02/03</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>4.0</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643,037_258</th>\n",
       "      <td>Y</td>\n",
       "      <td>ERS015</td>\n",
       "      <td>2/9/2016</td>\n",
       "      <td>ERS015</td>\n",
       "      <td>?</td>\n",
       "      <td>RRQ084</td>\n",
       "      <td>643,037</td>\n",
       "      <td>2/1/2016</td>\n",
       "      <td>4,339,445</td>\n",
       "      <td>2/9/2016 18:23:55.625</td>\n",
       "      <td>...</td>\n",
       "      <td>2/9/2016 13:02:29.510</td>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>customer call inquired about cancelling wants ...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>11.0</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643,037_258</th>\n",
       "      <td>Y</td>\n",
       "      <td>RRQ084</td>\n",
       "      <td>2/2/2016</td>\n",
       "      <td>RRQ084</td>\n",
       "      <td>?</td>\n",
       "      <td>ERS015</td>\n",
       "      <td>643,037</td>\n",
       "      <td>2/3/2016</td>\n",
       "      <td>4,315,800</td>\n",
       "      <td>2/2/2016 18:27:07.354</td>\n",
       "      <td>...</td>\n",
       "      <td>2/2/2016 08:44:49.802</td>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>02/1 So Mr. Mize doesn't want the door. Ella</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>11.0</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643,037_258</th>\n",
       "      <td>Y</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>VNDR</td>\n",
       "      <td>643,037</td>\n",
       "      <td>?</td>\n",
       "      <td>4,312,350</td>\n",
       "      <td>2/1/2016 18:24:26.853</td>\n",
       "      <td>...</td>\n",
       "      <td>2/1/2016 09:33:35.332</td>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>** FROM VNDR ATTN: PRODUCT SHIPPED ON 02/01/20...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>4.0</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643,037_258</th>\n",
       "      <td>Y</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>TAM5409</td>\n",
       "      <td>643,037</td>\n",
       "      <td>?</td>\n",
       "      <td>4,325,852</td>\n",
       "      <td>2/5/2016 18:22:29.095</td>\n",
       "      <td>...</td>\n",
       "      <td>2/5/2016 09:28:42.193</td>\n",
       "      <td>258</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1st Call to Schedule - 7 days- called customer...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>4.0</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631,853_258</th>\n",
       "      <td>Y</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>ERS015</td>\n",
       "      <td>631,853</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>11/12/2015 09:51:57.901</td>\n",
       "      <td>258</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11/12 Chassidy will be coming into the store t...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631,853_258</th>\n",
       "      <td>Y</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>ERS015</td>\n",
       "      <td>631,853</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>11/12/2015 09:53:43.555</td>\n",
       "      <td>258</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>11/12 I talk to Jeremy/Overhead to let him kno...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631,853_258</th>\n",
       "      <td>Y</td>\n",
       "      <td>?</td>\n",
       "      <td>11/13/2015</td>\n",
       "      <td>ERS015</td>\n",
       "      <td>?</td>\n",
       "      <td>INSTLR</td>\n",
       "      <td>631,853</td>\n",
       "      <td>11/13/2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>11/13/2015 16:44:07.342</td>\n",
       "      <td>258</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>**FROM D30 SVC PROV:11/13/15 INS/Joanne called...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631,853_258</th>\n",
       "      <td>Y</td>\n",
       "      <td>?</td>\n",
       "      <td>11/13/2015</td>\n",
       "      <td>ERS015</td>\n",
       "      <td>?</td>\n",
       "      <td>INSTLR</td>\n",
       "      <td>631,853</td>\n",
       "      <td>11/13/2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>11/13/2015 16:43:50.143</td>\n",
       "      <td>258</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>**FROM D30 SVC PROV:11/13/15 Calling HD to req...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631,853_258</th>\n",
       "      <td>Y</td>\n",
       "      <td>?</td>\n",
       "      <td>11/13/2015</td>\n",
       "      <td>ERS015</td>\n",
       "      <td>?</td>\n",
       "      <td>INSTLR</td>\n",
       "      <td>631,853</td>\n",
       "      <td>11/13/2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>11/13/2015 16:43:25.473</td>\n",
       "      <td>258</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>**FROM D30 SVC PROV:11/13/15 INS/Joanne called...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631,853_258</th>\n",
       "      <td>Y</td>\n",
       "      <td>?</td>\n",
       "      <td>11/13/2015</td>\n",
       "      <td>ERS015</td>\n",
       "      <td>?</td>\n",
       "      <td>INSTLR</td>\n",
       "      <td>631,853</td>\n",
       "      <td>11/13/2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>11/13/2015 16:43:19.121</td>\n",
       "      <td>258</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>**FROM D30 SVC PROV:11/13/15 Calling HD to req...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631,853_258</th>\n",
       "      <td>Y</td>\n",
       "      <td>ERS015</td>\n",
       "      <td>11/16/2015</td>\n",
       "      <td>ERS015</td>\n",
       "      <td>?</td>\n",
       "      <td>ERS015</td>\n",
       "      <td>631,853</td>\n",
       "      <td>11/16/2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>11/16/2015 18:03:14.882</td>\n",
       "      <td>258</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>11/13 Call Jeremy to see if they talk to the i...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631,853_258</th>\n",
       "      <td>Y</td>\n",
       "      <td>?</td>\n",
       "      <td>11/16/2015</td>\n",
       "      <td>ERS015</td>\n",
       "      <td>?</td>\n",
       "      <td>INSTLR</td>\n",
       "      <td>631,853</td>\n",
       "      <td>11/16/2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>11/16/2015 18:03:23.597</td>\n",
       "      <td>258</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>**FROM D30 SVC PROV:..cont  also be an extra c...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631,853_258</th>\n",
       "      <td>Y</td>\n",
       "      <td>?</td>\n",
       "      <td>11/16/2015</td>\n",
       "      <td>ERS015</td>\n",
       "      <td>?</td>\n",
       "      <td>INSTLR</td>\n",
       "      <td>631,853</td>\n",
       "      <td>11/16/2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>11/16/2015 18:03:04.692</td>\n",
       "      <td>258</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>**FROM D30 SVC PROV:11/16/2015 Spoke to Ins an...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631,853_258</th>\n",
       "      <td>Y</td>\n",
       "      <td>?</td>\n",
       "      <td>11/16/2015</td>\n",
       "      <td>XXS9561</td>\n",
       "      <td>?</td>\n",
       "      <td>ERS015</td>\n",
       "      <td>631,853</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>11/16/2015 19:49:30.163</td>\n",
       "      <td>258</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>11/16 I informed Chassidy that add'l cost per ...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631,853_258</th>\n",
       "      <td>Y</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>ERS015</td>\n",
       "      <td>631,853</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>11/20/2015 16:44:19.474</td>\n",
       "      <td>258</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>Other - 10 days- 11/20 waiting on the customer</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631,853_258</th>\n",
       "      <td>Y</td>\n",
       "      <td>?</td>\n",
       "      <td>12/11/2015</td>\n",
       "      <td>XXS9561</td>\n",
       "      <td>?</td>\n",
       "      <td>ERS015</td>\n",
       "      <td>631,853</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12/11/2015 15:33:25.109</td>\n",
       "      <td>258</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>12/08 Jeff: Customer request that her install ...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631,853_258</th>\n",
       "      <td>Y</td>\n",
       "      <td>?</td>\n",
       "      <td>12/11/2015</td>\n",
       "      <td>XXS9561</td>\n",
       "      <td>?</td>\n",
       "      <td>ERS015</td>\n",
       "      <td>631,853</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12/11/2015 14:33:37.582</td>\n",
       "      <td>258</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>12/08 Jeff:  Customer cancelled. Thanks Ella</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631,853_258</th>\n",
       "      <td>Y</td>\n",
       "      <td>ERS015</td>\n",
       "      <td>12/30/2015</td>\n",
       "      <td>ERS015</td>\n",
       "      <td>?</td>\n",
       "      <td>CMV407</td>\n",
       "      <td>631,853</td>\n",
       "      <td>12/24/2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12/30/2015 11:35:18.027</td>\n",
       "      <td>258</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Ella-Ms Avery LVM on Wednesday afternoon askin...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631,853_258</th>\n",
       "      <td>Y</td>\n",
       "      <td>CMV407</td>\n",
       "      <td>12/30/2015</td>\n",
       "      <td>CMV407</td>\n",
       "      <td>?</td>\n",
       "      <td>CMV407</td>\n",
       "      <td>631,853</td>\n",
       "      <td>12/24/2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12/30/2015 09:09:48.782</td>\n",
       "      <td>258</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>***Avery-see Ella</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631,853_258</th>\n",
       "      <td>Y</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>ERS015</td>\n",
       "      <td>631,853</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12/28/2015 09:29:34.046</td>\n",
       "      <td>258</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>12/28 Jeremy said that the install manager wil...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631,853_258</th>\n",
       "      <td>Y</td>\n",
       "      <td>?</td>\n",
       "      <td>1/11/2016</td>\n",
       "      <td>ERS015</td>\n",
       "      <td>?</td>\n",
       "      <td>INSTLR</td>\n",
       "      <td>631,853</td>\n",
       "      <td>1/7/2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1/11/2016 12:16:47.082</td>\n",
       "      <td>258</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>**FROM D30 SVC PROV:Can you please call us at ...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631,853_258</th>\n",
       "      <td>Y</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>ERS015</td>\n",
       "      <td>631,853</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1/14/2016 16:57:31.641</td>\n",
       "      <td>258</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>01/14Chassidy is having a problem finding somo...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631,853_258</th>\n",
       "      <td>Y</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>ERS015</td>\n",
       "      <td>631,853</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1/14/2016 16:58:05.633</td>\n",
       "      <td>258</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>01/14 I told her that I will call Jeff/Clopay ...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631,853_258</th>\n",
       "      <td>Y</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>ERS015</td>\n",
       "      <td>631,853</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1/15/2016 11:36:38.489</td>\n",
       "      <td>258</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>Status: Awaiting Special Order - 7 days- 01/15...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631,853_258</th>\n",
       "      <td>Y</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>ERS015</td>\n",
       "      <td>631,853</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2/3/2016 17:54:28.466</td>\n",
       "      <td>258</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Checking Status: Left Message - 2 days- 02/03 ...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631,853_258</th>\n",
       "      <td>Y</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>ERS015</td>\n",
       "      <td>631,853</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2/10/2016 13:20:22.717</td>\n",
       "      <td>258</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>Status: Customer not ready - 7 days- 02/10 Cha...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631,853_258</th>\n",
       "      <td>Y</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>ERS015</td>\n",
       "      <td>631,853</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2/17/2016 13:41:20.186</td>\n",
       "      <td>258</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>2/17 Customer will be coming in to return the ...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631,853_258</th>\n",
       "      <td>Y</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>ERS015</td>\n",
       "      <td>631,853</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2/17/2016 13:42:27.117</td>\n",
       "      <td>258</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>02/17 I had to add a busted trip charge for th...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631,853_258</th>\n",
       "      <td>Y</td>\n",
       "      <td>?</td>\n",
       "      <td>2/17/2016</td>\n",
       "      <td>ERS015</td>\n",
       "      <td>?</td>\n",
       "      <td>INSTLR</td>\n",
       "      <td>631,853</td>\n",
       "      <td>2/17/2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2/17/2016 15:56:25.693</td>\n",
       "      <td>258</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>**FROM D30 SVC PROV:2/17/16 Related to PO#2149...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631,853_258</th>\n",
       "      <td>Y</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>SNS1871</td>\n",
       "      <td>631,853</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2/19/2016 11:29:38.921</td>\n",
       "      <td>258</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Customer Not Ready - 7 days- no action taken w...</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ACTV_FLG ASSG_ASSOC_USER_ID      CLS_DT CLS_USER_AUD_ID CRT_SRC_MOD_ID CRT_USER_AUD_ID CUST_ORD_NBR  FLLW_UP_DT LAST_UPD_SNSH_ID             LAST_UPD_TS  ...            SRC_LAST_UPD_TS STR_LOC_ID SVC_LINE_NBR  SVC_NOTE_NBR  \\\n",
       "CUST_LOC                                                                                                                                                              ...                                                                    \n",
       "643,037_258        Y                  ?           ?               ?              ?         MRT1803      643,037           ?        4,258,089  1/16/2016 18:27:16.595  ...     1/16/2016 14:57:24.905        258            1             1   \n",
       "643,037_258        Y                  ?           ?               ?              ?          ERS015      643,037           ?        4,275,111  1/21/2016 18:21:16.529  ...     1/21/2016 11:15:35.507        258            1             2   \n",
       "643,037_258        Y                  ?           ?               ?              ?          ERS015      643,037           ?        4,275,111  1/21/2016 18:21:16.498  ...     1/21/2016 11:30:39.932        258            2             1   \n",
       "643,037_258        Y                  ?           ?               ?              ?          ERS015      643,037           ?        4,302,184  1/29/2016 18:23:40.695  ...     1/29/2016 11:52:20.274        258            1             3   \n",
       "643,037_258        Y             ERS015    2/9/2016          ERS015              ?          RRQ084      643,037    2/1/2016        4,339,445   2/9/2016 18:23:55.625  ...      2/9/2016 13:02:29.510        258            1             4   \n",
       "643,037_258        Y             RRQ084    2/2/2016          RRQ084              ?          ERS015      643,037    2/3/2016        4,315,800   2/2/2016 18:27:07.354  ...      2/2/2016 08:44:49.802        258            1             5   \n",
       "643,037_258        Y                  ?           ?               ?              ?            VNDR      643,037           ?        4,312,350   2/1/2016 18:24:26.853  ...      2/1/2016 09:33:35.332        258            1             6   \n",
       "643,037_258        Y                  ?           ?               ?              ?         TAM5409      643,037           ?        4,325,852   2/5/2016 18:22:29.095  ...      2/5/2016 09:28:42.193        258            2             2   \n",
       "631,853_258        Y                  ?           ?               ?              ?          ERS015      631,853           ?              NaN                     NaN  ...    11/12/2015 09:51:57.901        258            4             1   \n",
       "631,853_258        Y                  ?           ?               ?              ?          ERS015      631,853           ?              NaN                     NaN  ...    11/12/2015 09:53:43.555        258            4             2   \n",
       "631,853_258        Y                  ?  11/13/2015          ERS015              ?          INSTLR      631,853  11/13/2015              NaN                     NaN  ...    11/13/2015 16:44:07.342        258            2             1   \n",
       "631,853_258        Y                  ?  11/13/2015          ERS015              ?          INSTLR      631,853  11/13/2015              NaN                     NaN  ...    11/13/2015 16:43:50.143        258            2             2   \n",
       "631,853_258        Y                  ?  11/13/2015          ERS015              ?          INSTLR      631,853  11/13/2015              NaN                     NaN  ...    11/13/2015 16:43:25.473        258            4             3   \n",
       "631,853_258        Y                  ?  11/13/2015          ERS015              ?          INSTLR      631,853  11/13/2015              NaN                     NaN  ...    11/13/2015 16:43:19.121        258            4             4   \n",
       "631,853_258        Y             ERS015  11/16/2015          ERS015              ?          ERS015      631,853  11/16/2015              NaN                     NaN  ...    11/16/2015 18:03:14.882        258            4             5   \n",
       "631,853_258        Y                  ?  11/16/2015          ERS015              ?          INSTLR      631,853  11/16/2015              NaN                     NaN  ...    11/16/2015 18:03:23.597        258            2             3   \n",
       "631,853_258        Y                  ?  11/16/2015          ERS015              ?          INSTLR      631,853  11/16/2015              NaN                     NaN  ...    11/16/2015 18:03:04.692        258            2             4   \n",
       "631,853_258        Y                  ?  11/16/2015         XXS9561              ?          ERS015      631,853           ?              NaN                     NaN  ...    11/16/2015 19:49:30.163        258            5             1   \n",
       "631,853_258        Y                  ?           ?               ?              ?          ERS015      631,853           ?              NaN                     NaN  ...    11/20/2015 16:44:19.474        258            4             6   \n",
       "631,853_258        Y                  ?  12/11/2015         XXS9561              ?          ERS015      631,853           ?              NaN                     NaN  ...    12/11/2015 15:33:25.109        258            2             5   \n",
       "631,853_258        Y                  ?  12/11/2015         XXS9561              ?          ERS015      631,853           ?              NaN                     NaN  ...    12/11/2015 14:33:37.582        258            4             7   \n",
       "631,853_258        Y             ERS015  12/30/2015          ERS015              ?          CMV407      631,853  12/24/2015              NaN                     NaN  ...    12/30/2015 11:35:18.027        258            7             1   \n",
       "631,853_258        Y             CMV407  12/30/2015          CMV407              ?          CMV407      631,853  12/24/2015              NaN                     NaN  ...    12/30/2015 09:09:48.782        258            7             2   \n",
       "631,853_258        Y                  ?           ?               ?              ?          ERS015      631,853           ?              NaN                     NaN  ...    12/28/2015 09:29:34.046        258            7             3   \n",
       "631,853_258        Y                  ?   1/11/2016          ERS015              ?          INSTLR      631,853    1/7/2016              NaN                     NaN  ...     1/11/2016 12:16:47.082        258            7             4   \n",
       "631,853_258        Y                  ?           ?               ?              ?          ERS015      631,853           ?              NaN                     NaN  ...     1/14/2016 16:57:31.641        258            7             5   \n",
       "631,853_258        Y                  ?           ?               ?              ?          ERS015      631,853           ?              NaN                     NaN  ...     1/14/2016 16:58:05.633        258            7             6   \n",
       "631,853_258        Y                  ?           ?               ?              ?          ERS015      631,853           ?              NaN                     NaN  ...     1/15/2016 11:36:38.489        258            7             7   \n",
       "631,853_258        Y                  ?           ?               ?              ?          ERS015      631,853           ?              NaN                     NaN  ...      2/3/2016 17:54:28.466        258            7             8   \n",
       "631,853_258        Y                  ?           ?               ?              ?          ERS015      631,853           ?              NaN                     NaN  ...     2/10/2016 13:20:22.717        258            7             9   \n",
       "631,853_258        Y                  ?           ?               ?              ?          ERS015      631,853           ?              NaN                     NaN  ...     2/17/2016 13:41:20.186        258            7            10   \n",
       "631,853_258        Y                  ?           ?               ?              ?          ERS015      631,853           ?              NaN                     NaN  ...     2/17/2016 13:42:27.117        258            7            11   \n",
       "631,853_258        Y                  ?   2/17/2016          ERS015              ?          INSTLR      631,853   2/17/2016              NaN                     NaN  ...     2/17/2016 15:56:25.693        258            9             1   \n",
       "631,853_258        Y                  ?           ?               ?              ?         SNS1871      631,853           ?              NaN                     NaN  ...     2/19/2016 11:29:38.921        258            8             1   \n",
       "\n",
       "                                                  SVC_NOTE_TXT  TBIN_UPD_TS TBIN_UPD_USER_ID TKLR_BIN_CD UPD_SRC_MOD_ID  order  \n",
       "CUST_LOC                                                                                                                        \n",
       "643,037_258  Customer came in to check on the ETA of the order            ?                ?         4.0              ?      1  \n",
       "643,037_258                                    01/21 eta 01/27            ?                ?         4.0              ?      1  \n",
       "643,037_258  01/21 Clyde will be calling the store on 01/27...            ?                ?         4.0              ?      1  \n",
       "643,037_258                                    01/29 eta 02/03            ?                ?         4.0              ?      1  \n",
       "643,037_258  customer call inquired about cancelling wants ...            ?                ?        11.0              ?      1  \n",
       "643,037_258       02/1 So Mr. Mize doesn't want the door. Ella            ?                ?        11.0              ?      1  \n",
       "643,037_258  ** FROM VNDR ATTN: PRODUCT SHIPPED ON 02/01/20...            ?                ?         4.0              ?      1  \n",
       "643,037_258  1st Call to Schedule - 7 days- called customer...            ?                ?         4.0              ?      1  \n",
       "631,853_258  11/12 Chassidy will be coming into the store t...            ?                ?         NaN              ?      0  \n",
       "631,853_258  11/12 I talk to Jeremy/Overhead to let him kno...            ?                ?         NaN              ?      0  \n",
       "631,853_258  **FROM D30 SVC PROV:11/13/15 INS/Joanne called...            ?                ?         NaN              ?      0  \n",
       "631,853_258  **FROM D30 SVC PROV:11/13/15 Calling HD to req...            ?                ?         NaN              ?      0  \n",
       "631,853_258  **FROM D30 SVC PROV:11/13/15 INS/Joanne called...            ?                ?         NaN              ?      0  \n",
       "631,853_258  **FROM D30 SVC PROV:11/13/15 Calling HD to req...            ?                ?         NaN              ?      0  \n",
       "631,853_258  11/13 Call Jeremy to see if they talk to the i...            ?                ?         NaN              ?      0  \n",
       "631,853_258  **FROM D30 SVC PROV:..cont  also be an extra c...            ?                ?         NaN              ?      0  \n",
       "631,853_258  **FROM D30 SVC PROV:11/16/2015 Spoke to Ins an...            ?                ?         NaN              ?      0  \n",
       "631,853_258  11/16 I informed Chassidy that add'l cost per ...            ?                ?         NaN              ?      0  \n",
       "631,853_258     Other - 10 days- 11/20 waiting on the customer            ?                ?         NaN              ?      0  \n",
       "631,853_258  12/08 Jeff: Customer request that her install ...            ?                ?         NaN              ?      0  \n",
       "631,853_258       12/08 Jeff:  Customer cancelled. Thanks Ella            ?                ?         NaN              ?      0  \n",
       "631,853_258  Ella-Ms Avery LVM on Wednesday afternoon askin...            ?                ?         NaN              ?      0  \n",
       "631,853_258                                  ***Avery-see Ella            ?                ?         NaN              ?      0  \n",
       "631,853_258  12/28 Jeremy said that the install manager wil...            ?                ?         NaN              ?      0  \n",
       "631,853_258  **FROM D30 SVC PROV:Can you please call us at ...            ?                ?         NaN              ?      0  \n",
       "631,853_258  01/14Chassidy is having a problem finding somo...            ?                ?         NaN              ?      0  \n",
       "631,853_258  01/14 I told her that I will call Jeff/Clopay ...            ?                ?         NaN              ?      0  \n",
       "631,853_258  Status: Awaiting Special Order - 7 days- 01/15...            ?                ?         NaN              ?      0  \n",
       "631,853_258  Checking Status: Left Message - 2 days- 02/03 ...            ?                ?         NaN              ?      0  \n",
       "631,853_258  Status: Customer not ready - 7 days- 02/10 Cha...            ?                ?         NaN              ?      0  \n",
       "631,853_258  2/17 Customer will be coming in to return the ...            ?                ?         NaN              ?      0  \n",
       "631,853_258  02/17 I had to add a busted trip charge for th...            ?                ?         NaN              ?      0  \n",
       "631,853_258  **FROM D30 SVC PROV:2/17/16 Related to PO#2149...            ?                ?         NaN              ?      0  \n",
       "631,853_258  Customer Not Ready - 7 days- no action taken w...            ?                ?         NaN              ?      0  \n",
       "\n",
       "[34 rows x 22 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I would rather use SQL for the data manipulation so.... installed the pandasql package via the Conda CLI interface \n",
    "# (i.e., Anaconda Prompt) \n",
    "\n",
    "#from pandasql import PandaSQL \n",
    "#pdsql = PandaSQL()\n",
    "#pdsql(\"\"\"SELECT d.cust_ord_nbr, d.svc_line_nbr, d.crt_dt, d.stat_eff_ts, d.svc_typ_cd, d.svc_stat_cd, d.user_aud_id, d.\"order\" from done_notes d \"\"\",locals())\n",
    "#all_notes = pdsql(\"\"\"SELECT d.cust_ord_nbr, d.svc_line_nbr, d.crt_dt, d.stat_eff_ts, d.svc_typ_cd, d.svc_stat_cd, d.user_aud_id, d.\"order\",\n",
    "#                   c.\"order\" From done_notes d Join co_notes c On  d.cust_ord_nbr = c.cust_ord_nbr and d.str_loc_id   = d.str_loc_id\"\"\", locals())\n",
    "\n",
    "#all_notes = pd.concat([done_notes, co_notes])\n",
    "#all_notes[\"CUST_LOC\"] = all_notes.CUST_ORD_NBR.astype(str).str.cat(all_notes.STR_LOC_ID.astype(str), sep='_')\n",
    "#all_notes\n",
    "#all_notes_i = all_notes.set_index(['CUST_ORD_NBR','STR_LOC_ID'])  ## Hierarchical Index\n",
    "all_notes_i = all_notes.set_index(['CUST_LOC'])                   ## Single Index with combined Columns(created above)\n",
    "#idx = all_notes_i.index\n",
    "all_notes_i\n",
    "\n",
    "#type(pdsql)\n",
    "#pdsql(\"SELECT * from done_notes limit 5;\",locals())\n",
    "#local = locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# store the feature matrix (X) and response vector (y).  The pdsql function automatically creates a DataFrame\n",
    "X = pdsql(\"\"\"SELECT svc_note_txt,cust_loc from all_notes\"\"\",locals())\n",
    "y = pdsql(\"\"\"SELECT \"order\" from all_notes\"\"\",locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(34, 2)\n",
      "(34, 1)\n",
      "                                         SVC_NOTE_TXT     CUST_LOC\n",
      "0   Customer came in to check on the ETA of the order  643,037_258\n",
      "1                                     01/21 eta 01/27  643,037_258\n",
      "2   01/21 Clyde will be calling the store on 01/27...  643,037_258\n",
      "3                                     01/29 eta 02/03  643,037_258\n",
      "4   customer call inquired about cancelling wants ...  643,037_258\n",
      "5        02/1 So Mr. Mize doesn't want the door. Ella  643,037_258\n",
      "6   ** FROM VNDR ATTN: PRODUCT SHIPPED ON 02/01/20...  643,037_258\n",
      "7   1st Call to Schedule - 7 days- called customer...  643,037_258\n",
      "8   11/12 Chassidy will be coming into the store t...  631,853_258\n",
      "9   11/12 I talk to Jeremy/Overhead to let him kno...  631,853_258\n",
      "10  **FROM D30 SVC PROV:11/13/15 INS/Joanne called...  631,853_258\n",
      "11  **FROM D30 SVC PROV:11/13/15 Calling HD to req...  631,853_258\n",
      "12  **FROM D30 SVC PROV:11/13/15 INS/Joanne called...  631,853_258\n",
      "13  **FROM D30 SVC PROV:11/13/15 Calling HD to req...  631,853_258\n",
      "14  11/13 Call Jeremy to see if they talk to the i...  631,853_258\n",
      "15  **FROM D30 SVC PROV:..cont  also be an extra c...  631,853_258\n",
      "16  **FROM D30 SVC PROV:11/16/2015 Spoke to Ins an...  631,853_258\n",
      "17  11/16 I informed Chassidy that add'l cost per ...  631,853_258\n",
      "18     Other - 10 days- 11/20 waiting on the customer  631,853_258\n",
      "19  12/08 Jeff: Customer request that her install ...  631,853_258\n",
      "20       12/08 Jeff:  Customer cancelled. Thanks Ella  631,853_258\n",
      "21  Ella-Ms Avery LVM on Wednesday afternoon askin...  631,853_258\n",
      "22                                  ***Avery-see Ella  631,853_258\n",
      "23  12/28 Jeremy said that the install manager wil...  631,853_258\n",
      "24  **FROM D30 SVC PROV:Can you please call us at ...  631,853_258\n",
      "25  01/14Chassidy is having a problem finding somo...  631,853_258\n",
      "26  01/14 I told her that I will call Jeff/Clopay ...  631,853_258\n",
      "27  Status: Awaiting Special Order - 7 days- 01/15...  631,853_258\n",
      "28  Checking Status: Left Message - 2 days- 02/03 ...  631,853_258\n",
      "29  Status: Customer not ready - 7 days- 02/10 Cha...  631,853_258\n",
      "30  2/17 Customer will be coming in to return the ...  631,853_258\n",
      "31  02/17 I had to add a busted trip charge for th...  631,853_258\n",
      "32  **FROM D30 SVC PROV:2/17/16 Related to PO#2149...  631,853_258\n",
      "33  Customer Not Ready - 7 days- no action taken w...  631,853_258\n"
     ]
    }
   ],
   "source": [
    "# check the shapes of X and y\n",
    "print(type(X))\n",
    "print(type(y))\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "#print(y)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             order                                       SVC_NOTE_TXT  first_flg\n",
      "CUST_LOC                                                                        \n",
      "631,853_258      0  11/12 Chassidy will be coming into the store t...          1\n",
      "643,037_258      1  Customer came in to check on the ETA of the order          1\n",
      "             order                                       SVC_NOTE_TXT  last_flg\n",
      "CUST_LOC                                                                       \n",
      "631,853_258      0  Customer Not Ready - 7 days- no action taken w...         1\n",
      "643,037_258      1  1st Call to Schedule - 7 days- called customer...         1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVC_NOTE_TXT</th>\n",
       "      <th>first_flg</th>\n",
       "      <th>last_flg</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CUST_LOC</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>631,853_258</th>\n",
       "      <td>11/12 Chassidy will be coming into the store t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643,037_258</th>\n",
       "      <td>Customer came in to check on the ETA of the order</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631,853_258</th>\n",
       "      <td>Customer Not Ready - 7 days- no action taken w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643,037_258</th>\n",
       "      <td>1st Call to Schedule - 7 days- called customer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  SVC_NOTE_TXT  first_flg  last_flg  order\n",
       "CUST_LOC                                                                                  \n",
       "631,853_258  11/12 Chassidy will be coming into the store t...        1.0       NaN      0\n",
       "643,037_258  Customer came in to check on the ETA of the order        1.0       NaN      1\n",
       "631,853_258  Customer Not Ready - 7 days- no action taken w...        NaN       1.0      0\n",
       "643,037_258  1st Call to Schedule - 7 days- called customer...        NaN       1.0      1"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_notes_2 = pdsql(\"\"\"SELECT cust_loc,\"order\",svc_note_txt from all_notes\"\"\",locals())\n",
    "#all_notes_2.head(10)\n",
    "all_notes_f = all_notes_2.groupby(['CUST_LOC']).first()\n",
    "all_notes_f['first_flg'] = 1\n",
    "#Flag_FRecs.reset_index(inplace=True)\n",
    "##Flag_FRecs.ix[:2,['post_visid','date_time','first_flg','last_flg']]\n",
    "\n",
    "all_notes_l = all_notes_2.groupby(['CUST_LOC']).last()\n",
    "all_notes_l['last_flg'] = 1\n",
    "#Flag_LRecs.reset_index(inplace=True)\n",
    "##Flag_LRecs.ix[:2,['post_visid','date_time','first_flg','last_flg']]\n",
    "\n",
    "print(all_notes_f)\n",
    "print(all_notes_l)\n",
    "all_notes_2\n",
    "\n",
    "dataframes = [all_notes_f, all_notes_l]  # This is a List to just create the dataframes object (unecessary but illustrative)\n",
    "flag_all = pd.concat(dataframes)  # This is a dataframe\n",
    "flag_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUST_LOC</th>\n",
       "      <th>order</th>\n",
       "      <th>SVC_NOTE_TXT</th>\n",
       "      <th>first_flg</th>\n",
       "      <th>last_flg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>643,037_258</td>\n",
       "      <td>1</td>\n",
       "      <td>Customer came in to check on the ETA of the order</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>643,037_258</td>\n",
       "      <td>1</td>\n",
       "      <td>01/21 eta 01/27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>643,037_258</td>\n",
       "      <td>1</td>\n",
       "      <td>01/21 Clyde will be calling the store on 01/27...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>643,037_258</td>\n",
       "      <td>1</td>\n",
       "      <td>01/29 eta 02/03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>643,037_258</td>\n",
       "      <td>1</td>\n",
       "      <td>customer call inquired about cancelling wants ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>643,037_258</td>\n",
       "      <td>1</td>\n",
       "      <td>02/1 So Mr. Mize doesn't want the door. Ella</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>643,037_258</td>\n",
       "      <td>1</td>\n",
       "      <td>** FROM VNDR ATTN: PRODUCT SHIPPED ON 02/01/20...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>643,037_258</td>\n",
       "      <td>1</td>\n",
       "      <td>1st Call to Schedule - 7 days- called customer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>631,853_258</td>\n",
       "      <td>0</td>\n",
       "      <td>11/12 Chassidy will be coming into the store t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>631,853_258</td>\n",
       "      <td>0</td>\n",
       "      <td>11/12 I talk to Jeremy/Overhead to let him kno...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>631,853_258</td>\n",
       "      <td>0</td>\n",
       "      <td>**FROM D30 SVC PROV:11/13/15 INS/Joanne called...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>631,853_258</td>\n",
       "      <td>0</td>\n",
       "      <td>**FROM D30 SVC PROV:11/13/15 Calling HD to req...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>631,853_258</td>\n",
       "      <td>0</td>\n",
       "      <td>**FROM D30 SVC PROV:11/13/15 INS/Joanne called...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>631,853_258</td>\n",
       "      <td>0</td>\n",
       "      <td>**FROM D30 SVC PROV:11/13/15 Calling HD to req...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>631,853_258</td>\n",
       "      <td>0</td>\n",
       "      <td>11/13 Call Jeremy to see if they talk to the i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>631,853_258</td>\n",
       "      <td>0</td>\n",
       "      <td>**FROM D30 SVC PROV:..cont  also be an extra c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>631,853_258</td>\n",
       "      <td>0</td>\n",
       "      <td>**FROM D30 SVC PROV:11/16/2015 Spoke to Ins an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>631,853_258</td>\n",
       "      <td>0</td>\n",
       "      <td>11/16 I informed Chassidy that add'l cost per ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>631,853_258</td>\n",
       "      <td>0</td>\n",
       "      <td>Other - 10 days- 11/20 waiting on the customer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>631,853_258</td>\n",
       "      <td>0</td>\n",
       "      <td>12/08 Jeff: Customer request that her install ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>631,853_258</td>\n",
       "      <td>0</td>\n",
       "      <td>12/08 Jeff:  Customer cancelled. Thanks Ella</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>631,853_258</td>\n",
       "      <td>0</td>\n",
       "      <td>Ella-Ms Avery LVM on Wednesday afternoon askin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>631,853_258</td>\n",
       "      <td>0</td>\n",
       "      <td>***Avery-see Ella</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>631,853_258</td>\n",
       "      <td>0</td>\n",
       "      <td>12/28 Jeremy said that the install manager wil...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>631,853_258</td>\n",
       "      <td>0</td>\n",
       "      <td>**FROM D30 SVC PROV:Can you please call us at ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>631,853_258</td>\n",
       "      <td>0</td>\n",
       "      <td>01/14Chassidy is having a problem finding somo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>631,853_258</td>\n",
       "      <td>0</td>\n",
       "      <td>01/14 I told her that I will call Jeff/Clopay ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>631,853_258</td>\n",
       "      <td>0</td>\n",
       "      <td>Status: Awaiting Special Order - 7 days- 01/15...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>631,853_258</td>\n",
       "      <td>0</td>\n",
       "      <td>Checking Status: Left Message - 2 days- 02/03 ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>631,853_258</td>\n",
       "      <td>0</td>\n",
       "      <td>Status: Customer not ready - 7 days- 02/10 Cha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>631,853_258</td>\n",
       "      <td>0</td>\n",
       "      <td>2/17 Customer will be coming in to return the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>631,853_258</td>\n",
       "      <td>0</td>\n",
       "      <td>02/17 I had to add a busted trip charge for th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>631,853_258</td>\n",
       "      <td>0</td>\n",
       "      <td>**FROM D30 SVC PROV:2/17/16 Related to PO#2149...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>631,853_258</td>\n",
       "      <td>0</td>\n",
       "      <td>Customer Not Ready - 7 days- no action taken w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CUST_LOC  order                                       SVC_NOTE_TXT  first_flg  last_flg\n",
       "0   643,037_258      1  Customer came in to check on the ETA of the order        1.0       NaN\n",
       "1   643,037_258      1                                    01/21 eta 01/27        NaN       NaN\n",
       "2   643,037_258      1  01/21 Clyde will be calling the store on 01/27...        NaN       NaN\n",
       "3   643,037_258      1                                    01/29 eta 02/03        NaN       NaN\n",
       "4   643,037_258      1  customer call inquired about cancelling wants ...        NaN       NaN\n",
       "5   643,037_258      1       02/1 So Mr. Mize doesn't want the door. Ella        NaN       NaN\n",
       "6   643,037_258      1  ** FROM VNDR ATTN: PRODUCT SHIPPED ON 02/01/20...        NaN       NaN\n",
       "7   643,037_258      1  1st Call to Schedule - 7 days- called customer...        NaN       1.0\n",
       "8   631,853_258      0  11/12 Chassidy will be coming into the store t...        1.0       NaN\n",
       "9   631,853_258      0  11/12 I talk to Jeremy/Overhead to let him kno...        NaN       NaN\n",
       "10  631,853_258      0  **FROM D30 SVC PROV:11/13/15 INS/Joanne called...        NaN       NaN\n",
       "11  631,853_258      0  **FROM D30 SVC PROV:11/13/15 Calling HD to req...        NaN       NaN\n",
       "12  631,853_258      0  **FROM D30 SVC PROV:11/13/15 INS/Joanne called...        NaN       NaN\n",
       "13  631,853_258      0  **FROM D30 SVC PROV:11/13/15 Calling HD to req...        NaN       NaN\n",
       "14  631,853_258      0  11/13 Call Jeremy to see if they talk to the i...        NaN       NaN\n",
       "15  631,853_258      0  **FROM D30 SVC PROV:..cont  also be an extra c...        NaN       NaN\n",
       "16  631,853_258      0  **FROM D30 SVC PROV:11/16/2015 Spoke to Ins an...        NaN       NaN\n",
       "17  631,853_258      0  11/16 I informed Chassidy that add'l cost per ...        NaN       NaN\n",
       "18  631,853_258      0     Other - 10 days- 11/20 waiting on the customer        NaN       NaN\n",
       "19  631,853_258      0  12/08 Jeff: Customer request that her install ...        NaN       NaN\n",
       "20  631,853_258      0       12/08 Jeff:  Customer cancelled. Thanks Ella        NaN       NaN\n",
       "21  631,853_258      0  Ella-Ms Avery LVM on Wednesday afternoon askin...        NaN       NaN\n",
       "22  631,853_258      0                                  ***Avery-see Ella        NaN       NaN\n",
       "23  631,853_258      0  12/28 Jeremy said that the install manager wil...        NaN       NaN\n",
       "24  631,853_258      0  **FROM D30 SVC PROV:Can you please call us at ...        NaN       NaN\n",
       "25  631,853_258      0  01/14Chassidy is having a problem finding somo...        NaN       NaN\n",
       "26  631,853_258      0  01/14 I told her that I will call Jeff/Clopay ...        NaN       NaN\n",
       "27  631,853_258      0  Status: Awaiting Special Order - 7 days- 01/15...        NaN       NaN\n",
       "28  631,853_258      0  Checking Status: Left Message - 2 days- 02/03 ...        NaN       NaN\n",
       "29  631,853_258      0  Status: Customer not ready - 7 days- 02/10 Cha...        NaN       NaN\n",
       "30  631,853_258      0  2/17 Customer will be coming in to return the ...        NaN       NaN\n",
       "31  631,853_258      0  02/17 I had to add a busted trip charge for th...        NaN       NaN\n",
       "32  631,853_258      0  **FROM D30 SVC PROV:2/17/16 Related to PO#2149...        NaN       NaN\n",
       "33  631,853_258      0  Customer Not Ready - 7 days- no action taken w...        NaN       1.0"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_Recs = pdsql(\"\"\"Select a.*, b.first_flg, b.last_flg   \n",
    "       From all_notes_2 a   \n",
    "       left outer join flag_all b\n",
    "       On  a.cust_loc = b.cust_loc\n",
    "       and a.svc_note_txt = b.svc_note_txt\"\"\", locals())\n",
    "       \n",
    "Final_Recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(type(all_notes_2))\n",
    "#print(all_notes_2)\n",
    "#all_notes_t = all_notes_2.T\n",
    "#all_notes_t\n",
    "#all_notes_t[\"all_txt\"] = [' '.join(row) for row in all_notes_t[all_notes_t.columns[:]].values]   ## Did not work\n",
    "#all_notes_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp_list = []\n",
    "temp_dict = {'CUST_LOC': row['CUST_LOC'], 'order': row['order'],   }\n",
    "                     \n",
    "\n",
    "# Loop through the records to create the ADS\n",
    "n = 0\n",
    "for index, row in Final_Recs.iterrows():  # if you don't include index then \"TypeError: tuple indices must be integers or slices, not str\"\n",
    "    #print('top o the for statement')\n",
    "    #print('evar4 =', (row['evar4 ']))\n",
    "    #print ('first_flg=', CR_merge['first_flg_y'][n])\n",
    "    \n",
    "    if row['first_flg'] == 1 :  # This is to start the build of the Cust_Loc single notes variable\n",
    "        temp_list = []\n",
    "        temp_list.append(row['SVC_NOTE_TXT'])\n",
    "    elif row['last_flg'] == 1:\n",
    "        temp_list.append(row['SVC_NOTE_TXT'])\n",
    "        ##temp_list = []\n",
    "    else:\n",
    "        temp_list.append(row['SVC_NOTE_TXT'])\n",
    "        \n",
    "    \n",
    "    ##    temp_list.append(temp_dict)\n",
    "\n",
    "## out = pd.DataFrame(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11/12 Chassidy will be coming into the store to pay the bal. due on the 2nd install that was left off the order in error. Ella',\n",
       " '11/12 I talk to Jeremy/Overhead to let him know that the 2nd po was added for the 2nd GDO. He will inform the installer.',\n",
       " '**FROM D30 SVC PROV:11/13/15 INS/Joanne called (she and tech both spoke with JM yesterday) Need trip charge for the dead run. First cust had2nd Po created since she had 2 gdos but beam prevented install(JS) : XML,SYSTEM',\n",
       " '**FROM D30 SVC PROV:11/13/15 Calling HD to request trip charge - the two POs are21491465 and 21491503. I have beenon hold for 13 minutes andno one at HD answered -sending emaill to COS (JS) : XML,SYSTEM',\n",
       " '**FROM D30 SVC PROV:11/13/15 INS/Joanne called (she and tech both spoke with JM yesterday) Need trip charge for the dead run. First cust had2nd PO created since she had 2 gdos but beam prevented install(JS) : XML,SYSTEM',\n",
       " '**FROM D30 SVC PROV:11/13/15 Calling HD to request trip charge - the two POs are21491465 and 21491503. I have beenon hold for 13 minutes andno one at HD answered -sending email to COS (JS) : XML,SYSTEM',\n",
       " '11/13 Call Jeremy to see if they talk to the installer on what size GDO will be needed and call Chassidy back on Monday. She need different GDO due to the beam in the way.',\n",
       " '**FROM D30 SVC PROV:..cont  also be an extra charge. Informed HD. (JM) : XML,SYSTEM',\n",
       " '**FROM D30 SVC PROV:11/16/2015 Spoke to Ins and they advised the only way they could install the opener would be to put in a low head room track which would put the clearance around 7 feet. That would cont.. : XML,SYSTEM',\n",
       " \"11/16 I informed Chassidy that add'l cost per door to install the low head room track on her GDO would be $270 per door. She's going to think about it and call me back. Thanks Ella\",\n",
       " 'Other - 10 days- 11/20 waiting on the customer',\n",
       " '12/08 Jeff: Customer request that her install be cancelled. Thanks Ella',\n",
       " '12/08 Jeff:  Customer cancelled. Thanks Ella',\n",
       " 'Ella-Ms Avery LVM on Wednesday afternoon asking about her install. I called her back to let her know that you and the installation company were not working today and that you would contact her on Monday.',\n",
       " '***Avery-see Ella',\n",
       " '12/28 Jeremy said that the install manager will call the installer to find out how the customer will get the low head room track.',\n",
       " '**FROM D30 SVC PROV:Can you please call us at (800) 784-6964 to talk about revising this PO and creating a new PO please.  Thanks : BRIAN,PRICE',\n",
       " \"01/14Chassidy is having a problem finding somone to notch out the beam for the GDO to be installed. one man told her that he could drill a hole in the beam for the GDO to go through but the installer said that wouldn't work.\",\n",
       " '01/14 I told her that I will call Jeff/Clopay to see if they would be able to do the install. Ella',\n",
       " 'Status: Awaiting Special Order - 7 days- 01/15 waiting on Chassidy to email me pictures of the beam in her garage. Also Jen is checking to see if her tech took pictures.(to send to Clopay)',\n",
       " 'Checking Status: Left Message - 2 days- 02/03 Chassidy to send pictures of garage with beam in the way',\n",
       " 'Status: Customer not ready - 7 days- 02/10 Chassidy called me today. I lmom for her to call me back. Install on hold because of the beam in her garage. Ella',\n",
       " '2/17 Customer will be coming in to return the Garage door openers. Please issue refund.',\n",
       " '02/17 I had to add a busted trip charge for the 2nd installer because they were unable to do the install the 2nd time.',\n",
       " '**FROM D30 SVC PROV:2/17/16 Related to PO#21492074 (JL) : XML,SYSTEM',\n",
       " 'Customer Not Ready - 7 days- no action taken was garage door opener returned????']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to **build a model**, the features must be **numeric**, and every observation must have the **same features in the same order**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make a **prediction**, the new observation must have the **same features as the training observations**, both in number and meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Representing text as numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# example text for model training (SMS messages)\n",
    "simple_train = ['call you tonight', 'Call me a cab', 'please call me... PLEASE!']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    "\n",
    "> Text Analysis is a major application field for machine learning algorithms. However the raw data, a sequence of symbols cannot be fed directly to the algorithms themselves as most of them expect **numerical feature vectors with a fixed size** rather than the **raw text documents with variable length**.\n",
    "\n",
    "We will use [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) to \"convert text into a matrix of token counts\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import and instantiate CountVectorizer (with the default parameters)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learn the 'vocabulary' of the training data (occurs in-place)\n",
    "vect.fit(simple_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'cab', u'call', u'me', u'please', u'tonight', u'you']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the fitted vocabulary\n",
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x6 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 9 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform training data into a 'document-term matrix'\n",
    "simple_train_dtm = vect.transform(simple_train)\n",
    "simple_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 1, 1],\n",
       "       [1, 1, 1, 0, 0, 0],\n",
       "       [0, 1, 1, 2, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert sparse matrix to a dense matrix\n",
    "simple_train_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    0     1   0       0        1    1\n",
       "1    1     1   1       0        0    0\n",
       "2    0     1   1       2        0    0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(simple_train_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    "\n",
    "> In this scheme, features and samples are defined as follows:\n",
    "\n",
    "> - Each individual token occurrence frequency (normalized or not) is treated as a **feature**.\n",
    "> - The vector of all the token frequencies for a given document is considered a multivariate **sample**.\n",
    "\n",
    "> A **corpus of documents** can thus be represented by a matrix with **one row per document** and **one column per token** (e.g. word) occurring in the corpus.\n",
    "\n",
    "> We call **vectorization** the general process of turning a collection of text documents into numerical feature vectors. This specific strategy (tokenization, counting and normalization) is called the **Bag of Words** or \"Bag of n-grams\" representation. Documents are described by word occurrences while completely ignoring the relative position information of the words in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 2)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 3)\t2\n"
     ]
    }
   ],
   "source": [
    "# print the sparse matrix\n",
    "print(simple_train_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the [scikit-learn documentation](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction):\n",
    "\n",
    "> As most documents will typically use a very small subset of the words used in the corpus, the resulting matrix will have **many feature values that are zeros** (typically more than 99% of them).\n",
    "\n",
    "> For instance, a collection of 10,000 short text documents (such as emails) will use a vocabulary with a size in the order of 100,000 unique words in total while each document will use 100 to 1000 unique words individually.\n",
    "\n",
    "> In order to be able to **store such a matrix in memory** but also to **speed up operations**, implementations will typically use a **sparse representation** such as the implementations available in the `scipy.sparse` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# example text for model testing\n",
    "simple_test = [\"please don't call me\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make a **prediction**, the new observation must have the **same features as the training observations**, both in number and meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data into a document-term matrix (using existing vocabulary)\n",
    "simple_test_dtm = vect.transform(simple_test)\n",
    "simple_test_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cab</th>\n",
       "      <th>call</th>\n",
       "      <th>me</th>\n",
       "      <th>please</th>\n",
       "      <th>tonight</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cab  call  me  please  tonight  you\n",
       "0    0     1   1       1        0    0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the vocabulary and document-term matrix together\n",
    "pd.DataFrame(simple_test_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "\n",
    "- `vect.fit(train)` **learns the vocabulary** of the training data\n",
    "- `vect.transform(train)` uses the **fitted vocabulary** to build a document-term matrix from the training data\n",
    "- `vect.transform(test)` uses the **fitted vocabulary** to build a document-term matrix from the testing data (and **ignores tokens** it hasn't seen before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Reading the SMS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read file into Pandas from a URL\n",
    "url = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/sms.tsv'\n",
    "sms = pd.read_table(url, header=None, names=['label', 'message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# alternative: read file into Pandas using a relative path\n",
    "path = '../data/sms.tsv'\n",
    "sms = pd.read_table(path, header=None, names=['label', 'message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the shape\n",
    "sms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6   ham  Even my brother is not like to speak with me. ...\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8  spam  WINNER!! As a valued network customer you have...\n",
       "9  spam  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the first 10 rows\n",
    "sms.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the class distribution\n",
    "sms.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert label to a numerical variable\n",
    "sms['label_num'] = sms.label.map({'ham':0, 'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  label_num\n",
       "0   ham  Go until jurong point, crazy.. Available only ...          0\n",
       "1   ham                      Ok lar... Joking wif u oni...          0\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...          1\n",
       "3   ham  U dun say so early hor... U c already then say...          0\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...          0\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...          1\n",
       "6   ham  Even my brother is not like to speak with me. ...          0\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...          0\n",
       "8  spam  WINNER!! As a valued network customer you have...          1\n",
       "9  spam  Had your mobile 11 months or more? U R entitle...          1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that the conversion worked\n",
    "sms.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150L, 4L)\n",
      "(150L,)\n"
     ]
    }
   ],
   "source": [
    "# usual way to define X and y (from the iris data) for use with a MODEL\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572L,)\n",
      "(5572L,)\n"
     ]
    }
   ],
   "source": [
    "# required way to define X and y for use with COUNTVECTORIZER\n",
    "X = sms.message\n",
    "y = sms.label_num\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4179L,)\n",
      "(1393L,)\n"
     ]
    }
   ],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Vectorizing the SMS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate the vectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# learn training data vocabulary, then use it to create a document-term matrix\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# alternative: combine fit and transform into a single step\n",
    "X_train_dtm = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4179x7456 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 55209 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the document-term matrix\n",
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1393x7456 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 17604 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Building a Naive Bayes model\n",
    "\n",
    "We will use [Multinomial Naive Bayes](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html):\n",
    "\n",
    "> The multinomial Naive Bayes classifier is suitable for classification with **discrete features** (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import and instantiate a Multinomial Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using X_train_dtm (timing it with an IPython \"magic command\")\n",
    "%time nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98851399856424982"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1203,    5],\n",
       "       [  11,  174]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "574               Waiting for your call.\n",
       "3375             Also andros ice etc etc\n",
       "45      No calls..messages..missed calls\n",
       "3415             No pic. Please re-send.\n",
       "1988    No calls..messages..missed calls\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print message text for the false positives (meaning they were incorrectly classified as spam)\n",
    "X_test[y_test < y_pred_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3132    LookAtMe!: Thanks for your purchase of a video...\n",
       "5       FreeMsg Hey there darling it's been 3 week's n...\n",
       "3530    Xmas & New Years Eve tickets are now on sale f...\n",
       "684     Hi I'm sue. I am 20 years old and work as a la...\n",
       "1875    Would you like to see my XXX pics they are so ...\n",
       "1893    CALL 09090900040 & LISTEN TO EXTREME DIRTY LIV...\n",
       "4298    thesmszone.com lets you send free anonymous an...\n",
       "4949    Hi this is Amy, we will be sending you a free ...\n",
       "2821    INTERFLORA - It's not too late to order Inter...\n",
       "2247    Hi ya babe x u 4goten bout me?' scammers getti...\n",
       "4514    Money i have won wining number 946 wot do i do...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print message text for the false negatives (meaning they were incorrectly classified as ham)\n",
    "X_test[y_test > y_pred_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"LookAtMe!: Thanks for your purchase of a video clip from LookAtMe!, you've been charged 35p. Think you can do better? Why not send a video in a MMSto 32323.\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what do you notice about the false negatives?\n",
    "X_test[3132]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.87744864e-03,   1.83488846e-05,   2.07301295e-03, ...,\n",
       "         1.09026171e-06,   1.00000000e+00,   3.98279868e-09])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predicted probabilities for X_test_dtm (poorly calibrated)\n",
    "y_pred_prob = nb.predict_proba(X_test_dtm)[:, 1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98664310005369604"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate AUC\n",
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Comparing Naive Bayes with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import and instantiate a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 50 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using X_train_dtm\n",
    "%time logreg.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = logreg.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01269556,  0.00347183,  0.00616517, ...,  0.03354907,\n",
       "        0.99725053,  0.00157706])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predicted probabilities for X_test_dtm (well calibrated)\n",
    "y_pred_prob = logreg.predict_proba(X_test_dtm)[:, 1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9877961234745154"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99368176123143015"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate AUC\n",
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Calculating the \"spamminess\" of each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7456"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the vocabulary of X_train\n",
    "X_train_tokens = vect.get_feature_names()\n",
    "len(X_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'00', u'000', u'008704050406', u'0121', u'01223585236', u'01223585334', u'0125698789', u'02', u'0207', u'02072069400', u'02073162414', u'02085076972', u'021', u'03', u'04', u'0430', u'05', u'050703', u'0578', u'06', u'07', u'07008009200', u'07090201529', u'07090298926', u'07123456789', u'07732584351', u'07734396839', u'07742676969', u'0776xxxxxxx', u'07781482378', u'07786200117', u'078', u'07801543489', u'07808', u'07808247860', u'07808726822', u'07815296484', u'07821230901', u'07880867867', u'0789xxxxxxx', u'07946746291', u'0796xxxxxx', u'07973788240', u'07xxxxxxxxx', u'08', u'0800', u'08000407165', u'08000776320', u'08000839402', u'08000930705']\n"
     ]
    }
   ],
   "source": [
    "# examine the first 50 tokens\n",
    "print(X_train_tokens[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'yer', u'yes', u'yest', u'yesterday', u'yet', u'yetunde', u'yijue', u'ym', u'ymca', u'yo', u'yoga', u'yogasana', u'yor', u'yorge', u'you', u'youdoing', u'youi', u'youphone', u'your', u'youre', u'yourjob', u'yours', u'yourself', u'youwanna', u'yowifes', u'yoyyooo', u'yr', u'yrs', u'ything', u'yummmm', u'yummy', u'yun', u'yunny', u'yuo', u'yuou', u'yup', u'zac', u'zaher', u'zealand', u'zebra', u'zed', u'zeros', u'zhong', u'zindgi', u'zoe', u'zoom', u'zouk', u'zyada', u'\\xe8n', u'\\u3028ud']\n"
     ]
    }
   ],
   "source": [
    "# examine the last 50 tokens\n",
    "print(X_train_tokens[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0., ...,   1.,   1.,   1.],\n",
       "       [  5.,  23.,   2., ...,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes counts the number of times each token appears in each class\n",
    "nb.feature_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2L, 7456L)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows represent classes, columns represent tokens\n",
    "nb.feature_count_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of times each token appears across all HAM messages\n",
    "ham_token_count = nb.feature_count_[0, :]\n",
    "ham_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5.,  23.,   2., ...,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of times each token appears across all SPAM messages\n",
    "spam_token_count = nb.feature_count_[1, :]\n",
    "spam_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a DataFrame of tokens with their separate ham and spam counts\n",
    "tokens = pd.DataFrame({'token':X_train_tokens, 'ham':ham_token_count, 'spam':spam_token_count}).set_index('token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>very</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nasty</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>villa</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beloved</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textoperator</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ham  spam\n",
       "token                  \n",
       "very           64     2\n",
       "nasty           1     1\n",
       "villa           0     1\n",
       "beloved         1     0\n",
       "textoperator    0     2"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine 5 random DataFrame rows\n",
    "tokens.sample(5, random_state=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can use this to calculate the **\"spamminess\" of each token**, we need to avoid **dividing by zero** and account for the **class imbalance**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>very</th>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nasty</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>villa</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beloved</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textoperator</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ham  spam\n",
       "token                  \n",
       "very           65     3\n",
       "nasty           2     2\n",
       "villa           1     2\n",
       "beloved         2     1\n",
       "textoperator    1     3"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add 1 to ham and spam counts to avoid dividing by 0\n",
    "tokens['ham'] = tokens.ham + 1\n",
    "tokens['spam'] = tokens.spam + 1\n",
    "tokens.sample(5, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3617.,   562.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes counts the number of observations in each class\n",
    "nb.class_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>very</th>\n",
       "      <td>0.017971</td>\n",
       "      <td>0.005338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nasty</th>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.003559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>villa</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.003559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beloved</th>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.001779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textoperator</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.005338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ham      spam\n",
       "token                           \n",
       "very          0.017971  0.005338\n",
       "nasty         0.000553  0.003559\n",
       "villa         0.000276  0.003559\n",
       "beloved       0.000553  0.001779\n",
       "textoperator  0.000276  0.005338"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the ham and spam counts into frequencies\n",
    "tokens['ham'] = tokens.ham / nb.class_count_[0]\n",
    "tokens['spam'] = tokens.spam / nb.class_count_[1]\n",
    "tokens.sample(5, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "      <th>spam_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>very</th>\n",
       "      <td>0.017971</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>0.297044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nasty</th>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>6.435943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>villa</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>12.871886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beloved</th>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>3.217972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textoperator</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>19.307829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ham      spam  spam_ratio\n",
       "token                                       \n",
       "very          0.017971  0.005338    0.297044\n",
       "nasty         0.000553  0.003559    6.435943\n",
       "villa         0.000276  0.003559   12.871886\n",
       "beloved       0.000553  0.001779    3.217972\n",
       "textoperator  0.000276  0.005338   19.307829"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the ratio of spam-to-ham for each token\n",
    "tokens['spam_ratio'] = tokens.spam / tokens.ham\n",
    "tokens.sample(5, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "      <th>spam_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>claim</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.158363</td>\n",
       "      <td>572.798932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prize</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.135231</td>\n",
       "      <td>489.131673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150p</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.087189</td>\n",
       "      <td>315.361210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tone</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.085409</td>\n",
       "      <td>308.925267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guaranteed</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.076512</td>\n",
       "      <td>276.745552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.069395</td>\n",
       "      <td>251.001779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.065836</td>\n",
       "      <td>238.129893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www</th>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.129893</td>\n",
       "      <td>234.911922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.056940</td>\n",
       "      <td>205.950178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awarded</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.053381</td>\n",
       "      <td>193.078292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150ppm</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.051601</td>\n",
       "      <td>186.642349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uk</th>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.099644</td>\n",
       "      <td>180.206406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.048043</td>\n",
       "      <td>173.770463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ringtone</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.044484</td>\n",
       "      <td>160.898577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.042705</td>\n",
       "      <td>154.462633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mob</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.042705</td>\n",
       "      <td>154.462633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>co</th>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.078292</td>\n",
       "      <td>141.590747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collection</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.039146</td>\n",
       "      <td>141.590747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.037367</td>\n",
       "      <td>135.154804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.037367</td>\n",
       "      <td>135.154804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.037367</td>\n",
       "      <td>135.154804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10p</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.037367</td>\n",
       "      <td>135.154804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8007</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.035587</td>\n",
       "      <td>128.718861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.067616</td>\n",
       "      <td>122.282918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekly</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.033808</td>\n",
       "      <td>122.282918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tones</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.032028</td>\n",
       "      <td>115.846975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>land</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.032028</td>\n",
       "      <td>115.846975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.032028</td>\n",
       "      <td>115.846975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>national</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.030249</td>\n",
       "      <td>109.411032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.030249</td>\n",
       "      <td>109.411032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>went</th>\n",
       "      <td>0.012718</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.139912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ll</th>\n",
       "      <td>0.052530</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.135494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>told</th>\n",
       "      <td>0.013824</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.128719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feel</th>\n",
       "      <td>0.013824</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.128719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gud</th>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.126195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cos</th>\n",
       "      <td>0.014929</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.119184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>but</th>\n",
       "      <td>0.090683</td>\n",
       "      <td>0.010676</td>\n",
       "      <td>0.117731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amp</th>\n",
       "      <td>0.015206</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.117017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>something</th>\n",
       "      <td>0.015206</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.117017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sure</th>\n",
       "      <td>0.015206</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.117017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ok</th>\n",
       "      <td>0.061100</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>0.116488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <td>0.016312</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.109084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>morning</th>\n",
       "      <td>0.016865</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.105507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yeah</th>\n",
       "      <td>0.017694</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.100562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lol</th>\n",
       "      <td>0.017694</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.100562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anything</th>\n",
       "      <td>0.017971</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.099015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my</th>\n",
       "      <td>0.150401</td>\n",
       "      <td>0.014235</td>\n",
       "      <td>0.094646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doing</th>\n",
       "      <td>0.019077</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.093275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>way</th>\n",
       "      <td>0.019630</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.090647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ask</th>\n",
       "      <td>0.019630</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.090647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>already</th>\n",
       "      <td>0.019630</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.090647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>too</th>\n",
       "      <td>0.021841</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.081468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>come</th>\n",
       "      <td>0.048936</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>0.072723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>later</th>\n",
       "      <td>0.030688</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.057981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lor</th>\n",
       "      <td>0.032900</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.054084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>da</th>\n",
       "      <td>0.032900</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.054084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>she</th>\n",
       "      <td>0.035665</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.049891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>he</th>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.037858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lt</th>\n",
       "      <td>0.064142</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.027741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gt</th>\n",
       "      <td>0.064971</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.027387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7456 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ham      spam  spam_ratio\n",
       "token                                     \n",
       "claim       0.000276  0.158363  572.798932\n",
       "prize       0.000276  0.135231  489.131673\n",
       "150p        0.000276  0.087189  315.361210\n",
       "tone        0.000276  0.085409  308.925267\n",
       "guaranteed  0.000276  0.076512  276.745552\n",
       "18          0.000276  0.069395  251.001779\n",
       "cs          0.000276  0.065836  238.129893\n",
       "www         0.000553  0.129893  234.911922\n",
       "1000        0.000276  0.056940  205.950178\n",
       "awarded     0.000276  0.053381  193.078292\n",
       "150ppm      0.000276  0.051601  186.642349\n",
       "uk          0.000553  0.099644  180.206406\n",
       "500         0.000276  0.048043  173.770463\n",
       "ringtone    0.000276  0.044484  160.898577\n",
       "000         0.000276  0.042705  154.462633\n",
       "mob         0.000276  0.042705  154.462633\n",
       "co          0.000553  0.078292  141.590747\n",
       "collection  0.000276  0.039146  141.590747\n",
       "valid       0.000276  0.037367  135.154804\n",
       "2000        0.000276  0.037367  135.154804\n",
       "800         0.000276  0.037367  135.154804\n",
       "10p         0.000276  0.037367  135.154804\n",
       "8007        0.000276  0.035587  128.718861\n",
       "16          0.000553  0.067616  122.282918\n",
       "weekly      0.000276  0.033808  122.282918\n",
       "tones       0.000276  0.032028  115.846975\n",
       "land        0.000276  0.032028  115.846975\n",
       "http        0.000276  0.032028  115.846975\n",
       "national    0.000276  0.030249  109.411032\n",
       "5000        0.000276  0.030249  109.411032\n",
       "...              ...       ...         ...\n",
       "went        0.012718  0.001779    0.139912\n",
       "ll          0.052530  0.007117    0.135494\n",
       "told        0.013824  0.001779    0.128719\n",
       "feel        0.013824  0.001779    0.128719\n",
       "gud         0.014100  0.001779    0.126195\n",
       "cos         0.014929  0.001779    0.119184\n",
       "but         0.090683  0.010676    0.117731\n",
       "amp         0.015206  0.001779    0.117017\n",
       "something   0.015206  0.001779    0.117017\n",
       "sure        0.015206  0.001779    0.117017\n",
       "ok          0.061100  0.007117    0.116488\n",
       "said        0.016312  0.001779    0.109084\n",
       "morning     0.016865  0.001779    0.105507\n",
       "yeah        0.017694  0.001779    0.100562\n",
       "lol         0.017694  0.001779    0.100562\n",
       "anything    0.017971  0.001779    0.099015\n",
       "my          0.150401  0.014235    0.094646\n",
       "doing       0.019077  0.001779    0.093275\n",
       "way         0.019630  0.001779    0.090647\n",
       "ask         0.019630  0.001779    0.090647\n",
       "already     0.019630  0.001779    0.090647\n",
       "too         0.021841  0.001779    0.081468\n",
       "come        0.048936  0.003559    0.072723\n",
       "later       0.030688  0.001779    0.057981\n",
       "lor         0.032900  0.001779    0.054084\n",
       "da          0.032900  0.001779    0.054084\n",
       "she         0.035665  0.001779    0.049891\n",
       "he          0.047000  0.001779    0.037858\n",
       "lt          0.064142  0.001779    0.027741\n",
       "gt          0.064971  0.001779    0.027387\n",
       "\n",
       "[7456 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the DataFrame sorted by spam_ratio\n",
    "# note: use sort() instead of sort_values() for pandas 0.16.2 and earlier\n",
    "tokens.sort_values('spam_ratio', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.667259786476862"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up the spam_ratio for a given token\n",
    "tokens.loc['dating', 'spam_ratio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Creating a DataFrame from individual text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/ham_files\\\\email1.txt',\n",
       " '../data/ham_files\\\\email3.txt',\n",
       " '../data/ham_files\\\\email5.txt']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use glob to create a list of ham filenames\n",
    "import glob\n",
    "ham_filenames = glob.glob('../data/ham_files/*.txt')\n",
    "ham_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is a ham email.\\nIt has 2 lines.\\n',\n",
       " 'This is another ham email.\\n',\n",
       " 'This is yet another ham email.\\n']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the contents of the ham files into a list (each list element is one email)\n",
    "ham_text = []\n",
    "for filename in ham_filenames:\n",
    "    with open(filename) as f:\n",
    "        ham_text.append(f.read())\n",
    "ham_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is a spam email.\\n', 'This is another spam email.\\n']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# repeat this process for the spam files\n",
    "spam_filenames = glob.glob('../data/spam_files/*.txt')\n",
    "spam_text = []\n",
    "for filename in spam_filenames:\n",
    "    with open(filename) as f:\n",
    "        spam_text.append(f.read())\n",
    "spam_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is a ham email.\\nIt has 2 lines.\\n',\n",
       " 'This is another ham email.\\n',\n",
       " 'This is yet another ham email.\\n',\n",
       " 'This is a spam email.\\n',\n",
       " 'This is another spam email.\\n']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine the ham and spam lists\n",
    "all_text = ham_text + spam_text\n",
    "all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 1, 1]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of labels (ham=0, spam=1)\n",
    "all_labels = [0]*len(ham_text) + [1]*len(spam_text)\n",
    "all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>This is a ham email.\\nIt has 2 lines.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>This is another ham email.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>This is yet another ham email.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>This is a spam email.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>This is another spam email.\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                  message\n",
       "0      0  This is a ham email.\\nIt has 2 lines.\\n\n",
       "1      0             This is another ham email.\\n\n",
       "2      0         This is yet another ham email.\\n\n",
       "3      1                  This is a spam email.\\n\n",
       "4      1            This is another spam email.\\n"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the lists into a DataFrame\n",
    "pd.DataFrame({'label':all_labels, 'message':all_text})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
